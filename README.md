# semacrawl

The crawler just prints the sites visited and the crawl time.

The database is local so the memory use is limited, though access time is much faster than using a cloud db.

## Requirements

The `requests` library is great for any web crawling mechanisms.
`pip install requests`

`threading` was used to create a timer for the threads.

